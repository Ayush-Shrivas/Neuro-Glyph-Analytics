# -*- coding: utf-8 -*-
"""Artificial-Neural-Network_DIABETES_DATASET_.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1GRUl1nn_Lp4nAz31WchtcEO5I5GSWprQ

IMPORTING PYTHON LIBARARIES
"""

from numpy import array
from keras.models import Sequential #neural network defined in kears.model library
from keras.layers import Dense #for creating layers of neural network in keras.layer library
from matplotlib import pyplot
import pandas as pd
from google.colab import files

"""READING THE DATA SHEET"""

dataset=pd.read_csv('diabetes.csv')
dataset.tail(10)

"""SEPARATING X COLUMNS AND Y COLUMNS BY SLICE OPERARTION"""

X= dataset.iloc[:,0:8].values #iloc =index location of columns 8 columns in x variables
Y= dataset.iloc[:,8].values
print(X)
print(Y)

"""ACTIVATING THE FUNCTION"""

model= Sequential() #to create simple artificial neural network
model.add(Dense(50, input_dim=8, activation='relu'))
model.add(Dense(20, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(1, activation='sigmoid'))

"""SPLIITING THE DATA INTO TRAIN AND TEST DATA"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

"""MAKING THE MODEL READY"""

#compile the keras model
#Modal 1
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#fit the model
history=model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=35, batch_size=15)
pyplot.plot(history.history['accuracy'])
pyplot.show()
accuracy = model.evaluate(X_test, y_test)
print('Accuracy: %.2f' % (accuracy[1]*100))

#Modal 2
#ACTIVATING THE FUNCTION
model= Sequential() #to create simple artificial neural network
model.add(Dense(80, input_dim=8, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(80, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
#MAKING THE MODEL READY
#compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#fit the model
history=model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=35, batch_size=20)
pyplot.plot(history.history['accuracy'])
pyplot.show()
accuracy = model.evaluate(X_test, y_test)
print('Accuracy: %.2f' % (accuracy[1]*100))

#Modal 3
#ACTIVATING THE FUNCTION
model= Sequential() #to create simple artificial neural network
model.add(Dense(50, input_dim=8, activation='relu'))
model.add(Dense(15, activation='relu'))
model.add(Dense(50, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
#MAKING THE MODEL READY
#compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#fit the model
history=model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=35, batch_size=10)
pyplot.plot(history.history['accuracy'])
pyplot.show()
accuracy = model.evaluate(X_test, y_test)
print('Accuracy: %.2f' % (accuracy[1]*100))

#Modal 4
#ACTIVATING THE FUNCTION
model= Sequential() #to create simple artificial neural network
model.add(Dense(55, input_dim=8, activation='relu'))
model.add(Dense(15, activation='relu'))
model.add(Dense(55, activation='relu'))
model.add(Dense(1, activation='sigmoid'))
#MAKING THE MODEL READY
#compile the keras model
model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
#fit the model
history=model.fit(X_train, y_train, validation_data=(X_test,y_test), epochs=35, batch_size=10)
pyplot.plot(history.history['accuracy'])
pyplot.show()
accuracy = model.evaluate(X_test, y_test)
print('Accuracy: %.2f' % (accuracy[1]*100))

# -*- coding: utf-8 -*-
"""
REVISED SCRIPT TO TRAIN AND STORE RESULTS FOR FOUR MODELS
"""

# IMPORTING PYTHON LIBARARIES
import pandas as pd
import numpy as np
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

# READING THE DATA SHEET
# Make sure 'diabetes.csv' is in the same directory or uploaded to your environment
dataset=pd.read_csv('diabetes.csv')

# SEPARATING X AND Y COLUMNS
X = dataset.iloc[:,0:8].values
Y = dataset.iloc[:,8].values

# SPLITTING THE DATA INTO TRAIN AND TEST SETS
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=0)

# --- MODEL TRAINING ---

# Lists to store results from each model
histories = []
final_accuracies = []
model_names = ['Model 1', 'Model 2', 'Model 3', 'Model 4']

print("--- Starting Model Training ---")

# --- Model 1 ---
model1 = Sequential([
    Dense(50, input_dim=8, activation='relu'),
    Dense(20, activation='relu'),
    Dense(50, activation='relu'),
    Dense(1, activation='sigmoid')
])
model1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history1 = model1.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=35, batch_size=15, verbose=0)
histories.append(history1)
accuracy1 = model1.evaluate(X_test, y_test, verbose=0)
final_accuracies.append(accuracy1[1])
print(f"Model 1 Final Accuracy: {accuracy1[1]*100:.2f}%")

# --- Model 2 ---
model2 = Sequential([
    Dense(80, input_dim=8, activation='relu'),
    Dense(50, activation='relu'),
    Dense(80, activation='relu'),
    Dense(1, activation='sigmoid')
])
model2.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history2 = model2.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=35, batch_size=20, verbose=0)
histories.append(history2)
accuracy2 = model2.evaluate(X_test, y_test, verbose=0)
final_accuracies.append(accuracy2[1])
print(f"Model 2 Final Accuracy: {accuracy2[1]*100:.2f}%")

# --- Model 3 ---
model3 = Sequential([
    Dense(50, input_dim=8, activation='relu'),
    Dense(15, activation='relu'),
    Dense(50, activation='relu'),
    Dense(1, activation='sigmoid')
])
model3.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history3 = model3.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=35, batch_size=10, verbose=0)
histories.append(history3)
accuracy3 = model3.evaluate(X_test, y_test, verbose=0)
final_accuracies.append(accuracy3[1])
print(f"Model 3 Final Accuracy: {accuracy3[1]*100:.2f}%")

# --- Model 4 ---
model4 = Sequential([
    Dense(55, input_dim=8, activation='relu'),
    Dense(15, activation='relu'),
    Dense(55, activation='relu'),
    Dense(1, activation='sigmoid')
])
model4.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
history4 = model4.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=35, batch_size=10, verbose=0)
histories.append(history4)
accuracy4 = model4.evaluate(X_test, y_test, verbose=0)
final_accuracies.append(accuracy4[1])
print(f"Model 4 Final Accuracy: {accuracy4[1]*100:.2f}%")

print("\n--- Model Training Complete ---")

# -*- coding: utf-8 -*-
"""
DiabeNet_Predictor_Report_Generator.py

This script trains four neural network models, evaluates their performance,
and generates a single, interactive, and visually advanced HTML file.
The final report includes professional summaries for each visualization.
"""

# --- 1. IMPORTING NECESSARY LIBRARIES ---
import pandas as pd
from keras.models import Sequential
from keras.layers import Dense, Input
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import io
import base64
import warnings

# Suppress Keras UserWarning about using 'input_dim'
warnings.filterwarnings("ignore", category=UserWarning)

print("Libraries imported successfully.")

# --- 2. READING AND PREPARING THE DATA ---
try:
    # Ensure 'diabetes.csv' is in your environment
    dataset = pd.read_csv('diabetes.csv')
    X = dataset.iloc[:, 0:8].values
    Y = dataset.iloc[:, 8].values
    X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)
    print("Data loaded and split successfully.")
except FileNotFoundError:
    print("Error: 'diabetes.csv' not found. Please make sure the file is in the correct directory.")
    exit()


# --- 3. DEFINING AND TRAINING THE MODELS ---
def get_models():
    models = [
        (Sequential([Input(shape=(8,)), Dense(50, activation='relu'), Dense(20, activation='relu'), Dense(50, activation='relu'), Dense(1, activation='sigmoid')]), 15),
        (Sequential([Input(shape=(8,)), Dense(80, activation='relu'), Dense(50, activation='relu'), Dense(80, activation='relu'), Dense(1, activation='sigmoid')]), 20),
        (Sequential([Input(shape=(8,)), Dense(50, activation='relu'), Dense(15, activation='relu'), Dense(50, activation='relu'), Dense(1, activation='sigmoid')]), 10),
        (Sequential([Input(shape=(8,)), Dense(55, activation='relu'), Dense(15, activation='relu'), Dense(55, activation='relu'), Dense(1, activation='sigmoid')]), 10)
    ]
    return models

models_data = get_models()
histories = []
final_accuracies = []
model_names = ['Model 1', 'Model 2', 'Model 3', 'Model 4']

print("\n--- Starting Model Training ---")
for i, (model, batch_size) in enumerate(models_data):
    print(f"Training {model_names[i]}...")
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=35, batch_size=batch_size, verbose=0)
    histories.append(history)
    accuracy = model.evaluate(X_test, y_test, verbose=0)
    final_accuracies.append(accuracy[1])
    print(f"{model_names[i]} Final Accuracy: {accuracy[1]*100:.2f}%")
print("\n--- Model Training Complete ---")


# --- 4. GENERATING PLOTS AND ENCODING FOR HTML ---
def plot_to_base64(fig):
    buf = io.BytesIO()
    fig.savefig(buf, format='png', bbox_inches='tight', facecolor=fig.get_facecolor(), edgecolor='none', dpi=150)
    plt.close(fig)
    return base64.b64encode(buf.getvalue()).decode('utf-8')

print("Generating visualizations...")

plt.style.use('dark_background')
plot_face_color = '#1e2025'

# Plot 1: Validation Accuracy
fig1 = plt.figure(figsize=(10, 5.5), facecolor=plot_face_color)
ax1 = fig1.add_subplot(111, facecolor='#1e2025')
for i, history in enumerate(histories):
    ax1.plot(history.history['val_accuracy'], label=f'{model_names[i]}', linewidth=2.5)
ax1.set_xlabel('Epochs', fontsize=12, color='white')
ax1.set_ylabel('Accuracy', fontsize=12, color='white')
ax1.legend()
val_accuracy_b64 = plot_to_base64(fig1)

# Plot 2: Validation Loss
fig2 = plt.figure(figsize=(10, 5.5), facecolor=plot_face_color)
ax2 = fig2.add_subplot(111, facecolor='#1e2025')
for i, history in enumerate(histories):
    ax2.plot(history.history['val_loss'], label=f'{model_names[i]}', linewidth=2.5)
ax2.set_xlabel('Epochs', fontsize=12, color='white')
ax2.set_ylabel('Loss', fontsize=12, color='white')
ax2.legend()
val_loss_b64 = plot_to_base64(fig2)

# Plot 3: Final Accuracies Bar Chart
fig3 = plt.figure(figsize=(9, 6), facecolor=plot_face_color)
ax3 = fig3.add_subplot(111, facecolor='#1e2025')
bars = ax3.bar(model_names, final_accuracies, color=['#00aaff', '#00ffaa', '#ffaa00', '#ff00aa'])
ax3.set_xlabel('Models', fontsize=12, color='white')
ax3.set_ylabel('Accuracy', fontsize=12, color='white')
ax3.set_ylim(0, 1.05)
for bar in bars:
    yval = bar.get_height()
    ax3.text(bar.get_x() + bar.get_width()/2.0, yval + 0.01, f'{yval*100:.2f}%', va='bottom', ha='center', fontsize=12, fontweight='bold', color='white')
final_accuracy_b64 = plot_to_base64(fig3)

print("Visualizations generated successfully.")


# --- 5. CREATING THE ADVANCED HTML WEB PAGE WITH SUMMARIES ---

# Find the best performing model to mention it in the summary
best_model_index = final_accuracies.index(max(final_accuracies))
best_model_name = model_names[best_model_index]
best_model_accuracy = max(final_accuracies) * 100

html_content = f"""
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>DiabeNet Predictor | Performance Report</title>
    <link href="https://fonts.googleapis.com/css2?family=Poppins:wght@300;400;600&display=swap" rel="stylesheet">
    <style>
        :root {{
            --bg-color: #0d1117;
            --primary-color: #58a6ff;
            --card-bg: rgba(30, 35, 45, 0.7);
            --border-color: rgba(255, 255, 255, 0.1);
            --text-primary: #c9d1d9;
            --text-secondary: #8b949e;
        }}

        body {{
            font-family: 'Poppins', sans-serif;
            margin: 0;
            padding: 40px 20px;
            color: var(--text-primary);
            background-color: var(--bg-color);
            overflow: hidden;
            display: flex;
            justify-content: center;
            align-items: flex-start;
            min-height: 100vh;
        }}

        #particles-js {{
            position: fixed; width: 100%; height: 100%; top: 0; left: 0; z-index: -1;
        }}

        .container {{
            width: 90%; max-width: 1200px; background: var(--card-bg);
            backdrop-filter: blur(15px); -webkit-backdrop-filter: blur(15px);
            border-radius: 20px; border: 1px solid var(--border-color);
            box-shadow: 0 8px 32px 0 rgba(0, 0, 0, 0.37);
            padding: 40px; z-index: 1; overflow-y: auto; max-height: 90vh;
        }}

        header {{ text-align: center; margin-bottom: 40px; }}
        header h1 {{ margin: 0; font-weight: 600; font-size: 2.8em; color: #fff; }}
        header p {{ margin: 5px 0 0; font-weight: 300; font-size: 1.3em; color: var(--text-secondary); }}

        .tabs {{ display: flex; justify-content: center; margin-bottom: 30px; flex-wrap: wrap; gap: 15px; }}
        .tab-button {{
            padding: 12px 30px; cursor: pointer; background: transparent;
            border: 1px solid var(--border-color); color: #f0f6fc; border-radius: 50px;
            font-size: 1.1em; font-weight: 400; transition: all 0.3s ease;
        }}
        .tab-button:hover {{
            border-color: var(--primary-color); color: var(--primary-color);
            transform: translateY(-3px); box-shadow: 0 4px 15px rgba(88, 166, 255, 0.2);
        }}
        .tab-button.active {{
            background: var(--primary-color); color: var(--bg-color); font-weight: 600; border-color: var(--primary-color);
        }}

        @keyframes fadeInScaleUp {{ from {{ opacity: 0; transform: scale(0.95); }} to {{ opacity: 1; transform: scale(1); }} }}

        .plot-content {{
            display: none; padding: 25px; border-radius: 12px;
            background: var(--card-bg); border: 1px solid var(--border-color);
        }}
        .plot-content.active {{ display: block; animation: fadeInScaleUp 0.5s ease-out forwards; }}
        .plot-content img {{ max-width: 100%; height: auto; border-radius: 8px; }}

        .plot-title {{
            color: #f0f6fc; font-weight: 600; font-size: 1.5em;
            margin-top: 0; margin-bottom: 15px; text-align: center;
        }}
        .plot-summary {{
            font-size: 1em; font-weight: 300; color: var(--text-primary);
            text-align: left; margin-bottom: 25px; line-height: 1.6;
            border-left: 3px solid var(--primary-color); padding-left: 15px;
        }}

        footer {{ text-align: center; margin-top: 40px; font-size: 0.9em; color: var(--text-secondary); }}
    </style>
</head>
<body>
    <div id="particles-js"></div>
    <div class="container">
        <header>
            <h1>DiabeNet Predictor</h1>
            <p>ANN Performance Analysis Dashboard</p>
        </header>

        <div class="tabs">
            <button class="tab-button active" onclick="showPlot('finalAccuracy', this)">Final Accuracy</button>
            <button class="tab-button" onclick="showPlot('valAccuracy', this)">Validation Accuracy</button>
            <button class="tab-button" onclick="showPlot('valLoss', this)">Validation Loss</button>
        </div>

        <div id="finalAccuracy" class="plot-content active">
            <h2 class="plot-title">Executive Summary: Final Model Performance</h2>
            <p class="plot-summary">
                This chart provides a conclusive comparison of each model's final predictive accuracy on the unseen test dataset. <strong>{best_model_name}</strong> emerged as the most effective architecture, achieving the highest accuracy of <strong>{best_model_accuracy:.2f}%</strong>. This metric is the primary indicator of the model's generalization capability and real-world performance.
            </p>
            <img src="data:image/png;base64,{final_accuracy_b64}" alt="Final Accuracy Bar Chart">
        </div>

        <div id="valAccuracy" class="plot-content">
            <h2 class="plot-title">Analysis: Validation Accuracy Over Epochs</h2>
            <p class="plot-summary">
                This plot illustrates the learning progression by tracking accuracy on the validation set across 35 epochs. All models show a positive learning trend, with accuracy generally increasing and stabilizing. <strong>{best_model_name}</strong> not only achieved the highest final accuracy but also demonstrated a consistent and stable learning curve, indicating a robust and efficient training process.
            </p>
            <img src="data:image/png;base64,{val_accuracy_b64}" alt="Validation Accuracy Plot">
        </div>

        <div id="valLoss" class="plot-content">
            <h2 class="plot-title">Analysis: Validation Loss Over Epochs</h2>
            <p class="plot-summary">
                This chart tracks the error rate (loss) for each model during training. A decreasing loss signifies that a model is effectively learning to minimize prediction errors. All models demonstrate successful convergence as their loss values decrease and flatten, which suggests they have learned the patterns in the data without significant overfitting.
            </p>
            <img src="data:image/png;base64,{val_loss_b64}" alt="Validation Loss Plot">
        </div>

        <footer>
            <p>Interactive report generated on {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
        </footer>
    </div>

    <script src="https://cdn.jsdelivr.net/particles.js/2.0.0/particles.min.js"></script>
    <script>
        particlesJS("particles-js", {{
            "particles": {{"number": {{"value": 80,"density": {{"enable": true,"value_area": 800}}}},"color": {{"value": "#ffffff"}},"shape": {{"type": "circle"}},"opacity": {{"value": 0.5,"random": false}},"size": {{"value": 3,"random": true}},"line_linked": {{"enable": true,"distance": 150,"color": "#ffffff","opacity": 0.4,"width": 1}},"move": {{"enable": true,"speed": 2,"direction": "none","out_mode": "out"}}}},
            "interactivity": {{"detect_on": "canvas","events": {{"onhover": {{"enable": true,"mode": "repulse"}},"resize": true}},"modes": {{"repulse": {{"distance": 100,"duration": 0.4}}}}}},
            "retina_detect": true
        }});

        function showPlot(plotId, element) {{
            const plots = document.querySelectorAll('.plot-content');
            plots.forEach(plot => {{ plot.classList.remove('active'); }});
            const buttons = document.querySelectorAll('.tab-button');
            buttons.forEach(button => {{ button.classList.remove('active'); }});
            document.getElementById(plotId).classList.add('active');
            element.classList.add('active');
        }}
    </script>
</body>
</html>
"""

# --- 6. WRITING THE HTML FILE ---
report_filename = "DiabeNet_Predictor_Report.html"
with open(report_filename, "w") as f:
    f.write(html_content)

print(f"\n--- SUCCESS! ---")
print(f"Professional report '{report_filename}' has been created.")
print("Download the file and open it in your browser for the full experience. ðŸš€")